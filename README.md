# ğŸ™ï¸ Audio Transcription & Speaker Diarization

This project combines **OpenAI Whisper** and **PyAnnote Audio** to perform end-to-end **speech-to-text transcription** with **speaker diarization**. It identifies â€œwho spoke whenâ€ in an audio file and produces a clean JSON output mapping each segment to a speaker.

ğŸš€ Designed to run in a local environment (VS Code or any Python IDE) with GPU support for faster processing.

---

## âœ¨ Features

- âœ… **Speaker Diarization**: Distinguishes between multiple speakers in audio.
- âœ… **Speech-to-Text Transcription**: Converts spoken words to text using OpenAI Whisper.
- âœ… **Speaker Labeling**: Maps speakers to friendly names like `Speaker 1`, `Speaker 2`, etc.
- âœ… **JSON Output**: Saves a detailed transcript with timestamps and speaker IDs.
- âœ… **GPU Acceleration**: Automatically uses CUDA if available.
